{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "#from BCEmbedding.tools.langchain import BCERerank\n",
    "from FlagEmbedding import FlagReranker\n",
    "import pandas as pd\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from zhipuai import ZhipuAI\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"BAAI/bge-large-zh-v1.5\"\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "embedding = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    "    query_instruction=\"为这个句子生成表示以用于检索相关文章:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = FlagReranker('BAAI/bge-reranker-v2-m3', use_fp16=True) # Setting use_fp16 to True speeds up \n",
    "db = FAISS.load_local('../data/embedding_2048_512',embedding,allow_dangerous_deserialization = True)\n",
    "retriever=db.as_retriever( search_kwargs={\"k\":9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vipuser/miniconda3/envs/vllm/lib/python3.11/site-packages/langsmith/client.py:234: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt is: input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "print(f\"prompt is: {prompt}\")\n",
    "print(\"--------\")\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"GLM-4-PLus\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4\",\n",
    "    openai_api_key=\"3138eb04ab176ee38855bc7bd5883868.RZfclCazuZkKXA1f\",\n",
    "    streaming=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\".join(doc.page_content for doc in docs)\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPC 及 HA 服务中，verbose 参数的设置有几个级别？\n",
      "数据已写入到val_ans.jsonl文件中。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "extracted_data = []\n",
    "\n",
    "with open('../data/val.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        question = data['input_field']\n",
    "        prompt=\"以下问题只关于TuGraph-DB\\n\"+ question +\"\\n要求：直接回答结果，如果不知道回答不知道，不要添加额外内容，不要进行推测。回答长度不要超过100字。\"#提示词这块是需要工程化来做的\n",
    "        result = rag_chain_with_source.invoke(question)\n",
    "        extracted_info = {\"id\": data[\"id\"],\"output_field\": result['answer']}\n",
    "        extracted_data.append(extracted_info)\n",
    "        print(question,result['answer'])\n",
    "        print('\\n')\n",
    "#print(extracted_data)\n",
    "# 将提取的数据写入到answer.jsonl文件中\n",
    "with open('../result/val_ans.jsonl', 'w',encoding='utf-8') as f:\n",
    "    for item in extracted_data:\n",
    "        # 将每个字典转换为JSON格式的字符串，并写入文件\n",
    "        json_line = json.dumps(item,ensure_ascii=False) + '\\n'\n",
    "        f.write(json_line)\n",
    "print(\"数据已写入到val_ans.jsonl文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test1.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        question = data['input_field']\n",
    "        prompt=\"以下问题只关于TuGraph-DB\\n\"+ question +\"\\n要求：直接回答结果，如果不知道回答不知道，不要添加额外内容，不要进行推测。回答长度不要超过100字。\"#提示词这块是需要工程化来做的\n",
    "        result = rag_chain_with_source.invoke(question)\n",
    "        extracted_info = {\"id\": data[\"id\"],\"output_field\": result['answer']}\n",
    "        extracted_data.append(extracted_info)\n",
    "        print(question,result['answer'])\n",
    "        print('\\n')\n",
    "#print(extracted_data)\n",
    "# 将提取的数据写入到answer.jsonl文件中\n",
    "with open('result/answer2.jsonl', 'w',encoding='utf-8') as f:\n",
    "    for item in extracted_data:\n",
    "        # 将每个字典转换为JSON格式的字符串，并写入文件\n",
    "        json_line = json.dumps(item,ensure_ascii=False) + '\\n'\n",
    "        f.write(json_line)\n",
    "print(\"数据已写入到answer.jsonl文件中。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
