{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "#from BCEmbedding.tools.langchain import BCERerank\n",
    "from FlagEmbedding import FlagReranker\n",
    "import pandas as pd\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from zhipuai import ZhipuAI\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"BAAI/bge-large-zh-v1.5\"\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "embedding = HuggingFaceBgeEmbeddings(\n",
    "                model_name=model_name,\n",
    "                model_kwargs=model_kwargs,\n",
    "                encode_kwargs=encode_kwargs,\n",
    "                query_instruction=\"为这个句子生成表示以用于检索相关文章:\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = FlagReranker('BAAI/bge-reranker-v2-m3', use_fp16=True) # Setting use_fp16 to True speeds up \n",
    "db = FAISS.load_local('tu_document_1024_512',embedding,allow_dangerous_deserialization = True)\n",
    "retriever=db.as_retriever( search_kwargs={\"k\":9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(\n",
    "        model_name=\"GLM-4-PLus\",\n",
    "        openai_api_base=\"https://open.bigmodel.cn/api/paas/v4\",\n",
    "        openai_api_key=\"3138eb04ab176ee38855bc7bd5883868.RZfclCazuZkKXA1f\",\n",
    "        streaming=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\".join(doc.page_content for doc in docs)\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "extracted_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        question = data['input_field']\n",
    "        prompt=\"以下问题只关于TuGraph-DB\\n\"+ question +\"\\n要求：直接回答结果，如果不知道回答不知道，不要添加额外内容，不要进行推测。回答长度不要超过100字。\"#提示词这块是需要工程化来做的\n",
    "        result = rag_chain_with_source.invoke(question)\n",
    "        extracted_info = {\"id\": data[\"id\"],\"output_field\": result['answer']}\n",
    "        extracted_data.append(extracted_info)\n",
    "        print(question,result['answer'])\n",
    "        print('\\n')\n",
    "#print(extracted_data)\n",
    "# 将提取的数据写入到answer.jsonl文件中\n",
    "with open('val_ans.jsonl', 'w',encoding='utf-8') as f:\n",
    "    for item in extracted_data:\n",
    "        # 将每个字典转换为JSON格式的字符串，并写入文件\n",
    "        json_line = json.dumps(item,ensure_ascii=False) + '\\n'\n",
    "        f.write(json_line)\n",
    "print(\"数据已写入到val_ans.jsonl文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test1.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        question = data['input_field']\n",
    "        prompt=\"以下问题只关于TuGraph-DB\\n\"+ question +\"\\n要求：直接回答结果，如果不知道回答不知道，不要添加额外内容，不要进行推测。回答长度不要超过100字。\"#提示词这块是需要工程化来做的\n",
    "        result = rag_chain_with_source.invoke(question)\n",
    "        extracted_info = {\"id\": data[\"id\"],\"output_field\": result['answer']}\n",
    "        extracted_data.append(extracted_info)\n",
    "        print(question,result['answer'])\n",
    "        print('\\n')\n",
    "#print(extracted_data)\n",
    "# 将提取的数据写入到answer.jsonl文件中\n",
    "with open('answer2.jsonl', 'w',encoding='utf-8') as f:\n",
    "    for item in extracted_data:\n",
    "        # 将每个字典转换为JSON格式的字符串，并写入文件\n",
    "        json_line = json.dumps(item,ensure_ascii=False) + '\\n'\n",
    "        f.write(json_line)\n",
    "print(\"数据已写入到answer.jsonl文件中。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
